# -*- coding: utf-8 -*-
"""Proyecto_M7_Técnicas_avanzadas_para_ciencia_de_datos_y_empleabilidad_OscarKLópezG_

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SeFis9_00nbeW8isk_ME9cn3ks5jkRHM

## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

¡Éxito!

# Objetivos
- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

1. Selecciona uno de los siguientes *datasets*:
  - Imágenes de rayos X de pecho para detectar neumonía: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners
  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz

Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti. 

  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**. 

## Criterios de evaluación

| Actividad | Porcentaje | Observaciones | Punto parcial
| -- | -- | -- | -- |
| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

**Mucho éxito en tu camino como Data Scientist.**
"""

#Importación de librerias 
import pandas as pd 
import numpy as np
from google.colab import drive
import plotly.express as px
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/UCamp/Proyecto final /googleplaystore.csv') # vamos a leer el data frame 
df

df.info #usaremos .info para poder verificar que tipos de datos tenemos y verificar si hay Nans

df.info() # verificación de tipos de datos, este caso rating es el unico tipo de dato que es float para poder trabajar nuestros demas elementos hay que transformarlos

df['Reviews'] = df['Reviews'].astype(int) # esta linea de codigo vamos a volver los valores enteros para poder trabajarlo
# se tenia un error por un valor denominado 3.0M que al final se edito de manera manual para poder trabajar el df de manera correcta

df.info() # ya se tiene reviews como int64 que representa que son enteros

df.Price.sample(5) # se podia verificar en este caso algunos signos de pesos entonces realizaremos una función para quitarlos

Prueba = '$1.99' #dato de prueba

PR2 =Prueba.replace('$','') #con replace vamos a reemplazar algunos valores especiales 
# para poder pasar los datos a una cadena de texto que podamos ocupar para trabajar con la visualización de datos

float(PR2) # verificación en este caso la variable Prueba para ver si quita todos los signos especiales de la variable

remover_signo = lambda x: float(x.replace('$','')) # definiremos la función remover_signos para quitar los caracteres especiales en este caso $ y ''

df['Price'] = df['Price'].apply(lambda x: remover_signo(x)) #lo aplicaremos para la columna de price ya que tiene estos signos especiales

df['Installs'] # Verificaremos la columna de installs, vemos que igual manera tiene signos especiales

remover_signos = lambda x: float(x.replace('+','').replace(',','')) # realizaremos la función de remover_signos pero ahora con las comas , y los más +

remover_signos('3,000') # valor de prueba

df['Installs'] = df['Installs'].replace('Free', '0') #remplazaremos los valores que tienen la leyenda free por 0

df['Installs'] = df['Installs'].apply(lambda x: remover_signos(x)) # y implementaremos la función de remover_signos para quitar los caracteres especiales

df['Installs'] # verificamos que se hayan quitado los signos especiales

df['Size'].head() # ahora verificaremos la columna Size ya que tiene Ms y ks de megabyte y kilobyte

remover_signos_2 = lambda x: x.replace('M','').replace('+','').replace(',','') # retomaremos la función para remover pero sustituremos la M por un espacio

identificar = lambda x: 'k' if 'k' in x else 'M' #esta función nos apoyara que si llegaramos a encontrar un a k la sustiyuya por M y de este modo M se reemplazara por espacio

df['Size'] = df['Size'].apply(lambda x: remover_signos_2(x)) # aplicaremos la función para remover los valores especiales en este caso M

df['Size'].head() # verificación

df['Size'].apply(lambda x: identificar(x)).value_counts() #vamos a contar en este caso cuantas M y k hay en el df

df['Aux'] = df['Size'].apply(lambda x: identificar(x)) # vamos a ocupar una variable auxiliar para pasar todos los valores que tengamos en K a M dividiendo los valores K entre 1000 ya que son megabytes

def convertir_unidades(x): #esta es la función para convertir las unidades usando de referencia M para poder cambiar los valores de k
    if x[0] ==  'M':
        return float(x[1])
    else:
        return float(float(x[1].replace('k','').replace(',',''))/1000)

df['Size']=df[['Aux','Size']].apply(lambda x: convertir_unidades(x), axis=1) #aplicaremos la función antes mencionada a la columna Size

df.info() # verificamos nuevamente el df y ya hemos convertido los valores que nos interesan para poder realizar en este caso los calculos y visulización del proyecto

# vamos a empezar a realizar un pequeña grafíca de dispersión 
# en este caso se tomara de referencia la calificación contra las reseñas, en este caso se puede denotar que las aplicaciones que tienen calificación de 5 estrellas por lo general no manejan muchas reseñas y en efecto
# ya que al tener una calificación perfecta el producto en si es muy bueno y funciona optimamente
# pero donde se ve una tendencia más dispersa es cuando empieza a ver calificaciones 4.9 y 4.1 esto es un comportamiento de igualmanera regular ya que con base a las opiniones generales puede haber cosas que se pueden mejorar para obtener la califación perfecta

import plotly.express as px
fig = px.scatter(df, x="Reviews", y="Rating",title="Comportamiento de Reviews vs Rating")
fig.show()

# Ahora vamos a hacer una grafíca de pay diferenciando en este caso las categorias de las aplicaciones que vamos a analizar
# Podemos verificar en este caso que la categoria más ocupada en el df es la de games y family y la menos es una categoria llamada 1.9 y events
fig = px.pie(df, values='Installs', names='Category', title = 'Categorización de aplicaciones')
fig.show()

df.Type.value_counts() # realizaremos un value counts para verificar el tipo de cobro, si la app es de pago o gratis.

df['Type'] = df['Type'].replace('0','Free') # tenemos un dato denominado cero lo reemplazaremos por Free para que entre en las categorias antes mencionadas

df.Type.value_counts() # volveremos a hacer un conteo para divir en paga y gratis

# Vamos a hacer una grafíca de distribución acumulada, para verificar la tendencia del pago y de aplicaciones gratis 
fig = px.ecdf(df, x="Price", color="Type")
fig.show()

# Empezaremos importando las librerias para hacer el random forest 
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

param_grid = {
    'bootstrap': [True],
    'max_depth': [80, 90, 100, 110],
    'max_features': [2, 3],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 200, 300, 1000]
}

# Crearemos la cuadrícula de parámetros basada en los resultados de la búsqueda aleatoria para aplicar el random forest con grid search 
# https://www.w3schools.com/python/python_ml_grid_search.asp 
# https://www.w3schools.com/python/python_ml_grid_search.asp#:~:text=One%20method%20is%20to%20try,forming%20a%20grid%20of%20values.

def evaluate(model, test_features, test_labels):
    predictions = model.predict(test_features)
    errors = abs(predictions - test_labels)
    mape = 100 * np.mean(errors / test_labels)
    accuracy = 100 - mape
    print('Model Performance')
    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))
    print('Accuracy = {:0.2f}%.'.format(accuracy))
    
    return accuracy
    # esto seria parte del grid search

df = df.dropna() # quitaremos los Nas para la aplicación del modelo

df.shape # verificación del tamaño del df

X,y = df[['Size','Installs','Reviews']], df['Rating'] 
# vamos a definir nuestra X y y 

# ¿Cuál sería el rating una aplicación? (mediante el comportamiento de tamaño, instalación y reseñas)
# El modelo debería dar una respuesta promedio del rating de una nueva aplicación

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42) 


# vamos a definir nuestra x train, test y y train y test para poder correr nuestro train test split

rf = RandomForestRegressor()                                               # vamos a crear nuestro modelo random forest

grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          cv = 3, n_jobs = -1, verbose = 2)                #  vamos a verificar directamente el grid search

grid_search.fit(X_train, y_train)
grid_search.best_params_                                                   # vamos a correr el modelo para verificar que parametros nos arroga y posteriormente sacar nuestra evaluación del modelo

best_grid = grid_search.best_estimator_                          #  vamos a verificar la mejor puntación que nos brinda grid search

grid_accuracy = evaluate(best_grid, X_test, y_test)              # vamos a verificar el rendimiento del modelo seria de 89.98% y tenemos un Error promedio de 0.35%